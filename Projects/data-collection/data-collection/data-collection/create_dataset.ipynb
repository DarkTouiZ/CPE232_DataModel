{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pm25_data(file_paths, station_ids=['76T']):\n",
    "    all_pm25_data = []\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_excel(file_path, sheet_name='PM2.5')\n",
    "\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "        for station_id in station_ids:\n",
    "            if station_id in df.columns:\n",
    "                df_selected = df[['Date', station_id]]\n",
    "                df_selected.columns = ['date', 'pm25']\n",
    "                all_pm25_data.append(df_selected)\n",
    "\n",
    "    if all_pm25_data:\n",
    "        combined_df = pd.concat(all_pm25_data, ignore_index=True)\n",
    "        combined_df = combined_df.drop_duplicates(subset=['date']).reset_index(drop=True)\n",
    "        combined_df['pm25'] = pd.to_numeric(combined_df['pm25'], errors='coerce')\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(f\"ไม่พบข้อมูลสำหรับสถานี {station_id}\")\n",
    "        return pd.DataFrame(columns=['date', 'pm25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fire_data(file_path, station_lat, station_lng, inner_radius=20, outer_radius=50, start_date=None, end_date=None):\n",
    "    fire_df = pd.read_csv(file_path)\n",
    "\n",
    "    fire_df['acq_date'] = pd.to_datetime(fire_df['acq_date'])\n",
    "\n",
    "    if start_date is not None:\n",
    "        fire_df = fire_df[fire_df['acq_date'] >= pd.to_datetime(start_date)]\n",
    "    if end_date is not None:\n",
    "        fire_df = fire_df[fire_df['acq_date'] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    fire_df['distance'] = np.sqrt(\n",
    "        ((fire_df['latitude'] - station_lat) * 111.32)**2 +\n",
    "        ((fire_df['longitude'] - station_lng) * 111.32 * np.cos(np.radians(station_lat)))**2\n",
    "    )\n",
    "\n",
    "    fire_inner = fire_df[fire_df['distance'] <= inner_radius]\n",
    "    fire_outer = fire_df[(fire_df['distance'] > inner_radius) & (fire_df['distance'] <= outer_radius)]\n",
    "\n",
    "    if start_date is not None and end_date is not None:\n",
    "        all_dates = pd.DataFrame({'date': pd.date_range(start=start_date, end=end_date)})\n",
    "    else:\n",
    "        min_date = fire_df['acq_date'].min() if not fire_df.empty else pd.to_datetime('today')\n",
    "        max_date = fire_df['acq_date'].max() if not fire_df.empty else pd.to_datetime('today')\n",
    "        all_dates = pd.DataFrame({'date': pd.date_range(start=min_date, end=max_date)})\n",
    "\n",
    "    features_inner = fire_inner.groupby('acq_date').agg(\n",
    "        fire_count_inner=('acq_date', 'size'),\n",
    "        fire_frp_sum_inner=('frp', 'sum'),\n",
    "        fire_conf_inner=('confidence', 'mean')\n",
    "    ).reset_index().rename(columns={'acq_date': 'date'})\n",
    "    \n",
    "    features_outer = fire_outer.groupby('acq_date').agg(\n",
    "        fire_count_outer=('acq_date', 'size'),\n",
    "        fire_frp_sum_outer=('frp', 'sum'),\n",
    "        fire_conf_outer=('confidence', 'mean')\n",
    "    ).reset_index().rename(columns={'acq_date': 'date'})\n",
    "\n",
    "    result = all_dates.merge(features_inner, on='date', how='left').fillna(0)\n",
    "    result = result.merge(features_outer, on='date', how='left').fillna(0)\n",
    "\n",
    "    result['fire_count_total'] = result['fire_count_inner'] + result['fire_count_outer']\n",
    "    result['fire_frp_sum_total'] = result['fire_frp_sum_inner'] + result['fire_frp_sum_outer']\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather_data(file_paths):\n",
    "\n",
    "    # กำหนดตัวแปรที่จะใช้ข้อมูลจากทุกจุด\n",
    "    important_features = [\n",
    "        'temperature_2m_max (°C)', \n",
    "        'temperature_2m_mean (°C)', \n",
    "        'temperature_2m_min (°C)', \n",
    "        'precipitation_sum (mm)', \n",
    "        'wind_speed_10m_max (km/h)', \n",
    "        'wind_direction_10m_dominant (°)'\n",
    "    ]\n",
    "\n",
    "    center_only_features = [\n",
    "        'weather_code (wmo code)',\n",
    "        'cloud_cover_mean (%)', \n",
    "        'cloud_cover_max (%)', \n",
    "        'cloud_cover_min (%)',\n",
    "        'relative_humidity_2m_mean (%)',\n",
    "        'relative_humidity_2m_max (%)',\n",
    "        'relative_humidity_2m_min (%)',\n",
    "        'surface_pressure_mean (hPa)', \n",
    "        'surface_pressure_max (hPa)', \n",
    "        'surface_pressure_min (hPa)',\n",
    "        'winddirection_10m_dominant (°)',\n",
    "        'wind_speed_10m_mean (km/h)',\n",
    "        'wind_speed_10m_min (km/h)',\n",
    "        'vapour_pressure_deficit_max (kPa)'\n",
    "    ]\n",
    "    \n",
    "    locations = ['center', 'north', 'south', 'east', 'west']\n",
    "    combined_df = None\n",
    "    center_data = None\n",
    "    \n",
    "    for i, file_path in enumerate(file_paths):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, skiprows=3)\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['time'])\n",
    "\n",
    "            location = locations[i] if i < len(locations) else f\"location_{i}\"\n",
    "\n",
    "            if location == 'center':\n",
    "                available_cols = ['date'] \n",
    "\n",
    "                for col in center_only_features:\n",
    "                    if col in df.columns:\n",
    "                        available_cols.append(col)\n",
    "\n",
    "                for col in important_features:\n",
    "                    if col in df.columns:\n",
    "                        df = df.rename(columns={col: f\"{col}_{location}\"})\n",
    "                        available_cols.append(f\"{col}_{location}\")\n",
    "                \n",
    "                selected_df = df[available_cols].copy()\n",
    "\n",
    "                if combined_df is None:\n",
    "                    combined_df = selected_df\n",
    "                else:\n",
    "                    center_data = selected_df\n",
    "            else:\n",
    "                selected_cols = ['date']\n",
    "                renamed_cols = {}\n",
    "                \n",
    "                for col in important_features:\n",
    "                    if col in df.columns:\n",
    "                        renamed_cols[col] = f\"{col}_{location}\"\n",
    "                        selected_cols.append(col)\n",
    "                \n",
    "                if len(selected_cols) > 1:\n",
    "                    df_selected = df[selected_cols].copy()\n",
    "                    df_selected = df_selected.rename(columns=renamed_cols)\n",
    "                    \n",
    "                    if combined_df is not None:\n",
    "                        combined_df = pd.merge(combined_df, df_selected, on='date', how='outer')\n",
    "                    else:\n",
    "                        combined_df = df_selected\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"เกิดข้อผิดพลาดในการอ่านไฟล์ {file_path}: {e}\")\n",
    "\n",
    "    if center_data is not None and combined_df is not None:\n",
    "        center_cols = [col for col in center_data.columns if col not in combined_df.columns or col == 'date']\n",
    "        if len(center_cols) > 1:\n",
    "            center_data_selected = center_data[center_cols]\n",
    "            combined_df = pd.merge(combined_df, center_data_selected, on='date', how='outer')\n",
    "    \n",
    "    if combined_df is not None:\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"ไม่พบข้อมูลสภาพอากาศที่ใช้งานได้\")\n",
    "        return pd.DataFrame(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dataset(pm25_files, fire_file, weather_files, station_ids=['76T'], \n",
    "                            station_lat=116.746463959589768, station_lng=98.57437426524484,\n",
    "                            start_date='2019-01-01', end_date='2024-12-31'):\n",
    "    \n",
    "    # อ่านข้อมูล PM2.5 ✅\n",
    "    pm25_df = load_pm25_data(pm25_files, station_ids)\n",
    "    \n",
    "    # อ่านข้อมูลไฟป่า ✅\n",
    "    fire_df = load_fire_data(fire_file, station_lat, station_lng, start_date=start_date, end_date=end_date)\n",
    "    \n",
    "    # อ่านข้อมูลสภาพอากาศ ✅\n",
    "    weather_df = load_weather_data(weather_files)\n",
    "    \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    full_date_df = pd.DataFrame({'date': date_range})\n",
    "    \n",
    "    # รวมข้อมูลทั้งหมดเข้าด้วยกัน\n",
    "    combined_df = full_date_df.merge(pm25_df, on='date', how='left')\n",
    "    combined_df = combined_df.merge(fire_df, on='date', how='left')\n",
    "    combined_df = combined_df.merge(weather_df, on='date', how='left')\n",
    "    \n",
    "    fire_columns = [col for col in combined_df.columns if 'fire_count' in col]\n",
    "    combined_df[fire_columns] = combined_df[fire_columns].fillna(0)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = '76T'\n",
    "station_lat = 16.746463959589768 # center\n",
    "station_lng = 98.57437426524484 # center\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2024-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_files = sorted(glob.glob(\"dataset/PM2.5/PM2.5(*.xlsx\")) \n",
    "fire_file = \"dataset/Fire/fire_archive_M-C61_606028.csv\"\n",
    "weather_files = sorted(glob.glob(\"dataset/Weather_forecast/76T/*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = create_combined_dataset(\n",
    "    pm25_files, fire_file, weather_files, \n",
    "    [station_id], station_lat, station_lng,\n",
    "    start_date, end_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_dataset(combined_df, output_file='combined_pm25_dataset.csv'):\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"บันทึกชุดข้อมูลรวมเรียบร้อยแล้วที่ {output_file}\")\n",
    "    print(f\"จำนวนแถวทั้งหมด: {len(combined_df)}\")\n",
    "    print(f\"จำนวนคอลัมน์ทั้งหมด: {len(combined_df.columns)}\")\n",
    "    print(f\"คอลัมน์ในชุดข้อมูล: {combined_df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "บันทึกชุดข้อมูลรวมเรียบร้อยแล้วที่ dataset/Full/combined_pm25_76T_forecast_dataset.csv\n",
      "จำนวนแถวทั้งหมด: 2192\n",
      "จำนวนคอลัมน์ทั้งหมด: 54\n",
      "คอลัมน์ในชุดข้อมูล: ['date', 'pm25', 'fire_count_inner', 'fire_frp_sum_inner', 'fire_conf_inner', 'fire_count_outer', 'fire_frp_sum_outer', 'fire_conf_outer', 'fire_count_total', 'fire_frp_sum_total', 'weather_code (wmo code)', 'cloud_cover_mean (%)', 'cloud_cover_max (%)', 'cloud_cover_min (%)', 'relative_humidity_2m_mean (%)', 'relative_humidity_2m_max (%)', 'relative_humidity_2m_min (%)', 'surface_pressure_mean (hPa)', 'surface_pressure_max (hPa)', 'surface_pressure_min (hPa)', 'winddirection_10m_dominant (°)', 'wind_speed_10m_mean (km/h)', 'wind_speed_10m_min (km/h)', 'vapour_pressure_deficit_max (kPa)', 'temperature_2m_max (°C)_center', 'temperature_2m_mean (°C)_center', 'temperature_2m_min (°C)_center', 'precipitation_sum (mm)_center', 'wind_speed_10m_max (km/h)_center', 'wind_direction_10m_dominant (°)_center', 'temperature_2m_max (°C)_north', 'temperature_2m_mean (°C)_north', 'temperature_2m_min (°C)_north', 'precipitation_sum (mm)_north', 'wind_speed_10m_max (km/h)_north', 'wind_direction_10m_dominant (°)_north', 'temperature_2m_max (°C)_south', 'temperature_2m_mean (°C)_south', 'temperature_2m_min (°C)_south', 'precipitation_sum (mm)_south', 'wind_speed_10m_max (km/h)_south', 'wind_direction_10m_dominant (°)_south', 'temperature_2m_max (°C)_east', 'temperature_2m_mean (°C)_east', 'temperature_2m_min (°C)_east', 'precipitation_sum (mm)_east', 'wind_speed_10m_max (km/h)_east', 'wind_direction_10m_dominant (°)_east', 'temperature_2m_max (°C)_west', 'temperature_2m_mean (°C)_west', 'temperature_2m_min (°C)_west', 'precipitation_sum (mm)_west', 'wind_speed_10m_max (km/h)_west', 'wind_direction_10m_dominant (°)_west']\n"
     ]
    }
   ],
   "source": [
    "save_combined_dataset(combined_df, output_file=f'dataset/Full/combined_pm25_{station_id}_forecast_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
